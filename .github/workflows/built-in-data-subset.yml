name: built-in data-subset

on:
  # schedule:
  # - cron: '0 0 * * *' # Runs at midnight ET (us-east-1)
  workflow_dispatch:

env:
  PROD_DATABASE_URL: ${{ secrets.PROD_DATABASE_URL }}
  DEV_DATABASE_URL: ${{ secrets.DEV_DATABASE_URL }}

jobs:
  dump-and-restore:
    runs-on: ubuntu-latest

    steps:
      - name: Start PostgreSQL Service
        run: |
          sudo systemctl start postgresql.service

      - name: Dump schema
        run: |
          pg_dump "${{ env.PROD_DATABASE_URL }}" --schema-only --table=users -f "${{ github.workspace }}/users_schema.sql"

      - name: Dump data
        run: |
          psql "${{ env.PROD_DATABASE_URL }}" -c "\copy (SELECT * FROM users ORDER BY user_id DESC LIMIT 50) TO '${{ github.workspace }}/users_subset.csv' WITH CSV HEADER"

      - name: Drop tables
        run: |
          psql "${{ env.DEV_DATABASE_URL }}" -c "DROP TABLE IF EXISTS public.users CASCADE;"

      - name: Restore schema
        run: |
          psql "${{ env.DEV_DATABASE_URL }}" -f "${{ github.workspace }}/users_schema.sql"

      - name: Restore data
        run: |
          psql "${{ env.DEV_DATABASE_URL }}" -c "\copy public.users FROM '${{ github.workspace }}/users_subset.csv' WITH CSV HEADER"
