name: Create Neon Twin

on:
  schedule:
    - cron: '0 0 * * *' # Runs at midnight ET (us-east-1)
  workflow_dispatch:

env:
  PROD_DATABASE_URL: ${{ secrets.PROD_DATABASE_URL }}
  DEV_DATABASE_URL: ${{ secrets.DEV_DATABASE_URL }}
  PG_VERSION: '16'
  PG_WORK_DIR: '${{ github.workspace }}/pgcopydb'

jobs:
  dump-and-restore:
    runs-on: ubuntu-latest

    steps:
      - name: Install PostgreSQL
        run: |
          sudo apt update
          yes '' | sudo /usr/share/postgresql-common/pgdg/apt.postgresql.org.sh
          sudo apt install -y postgresql-${{ env.PG_VERSION }}

      - name: Set PostgreSQL binary path
        run: echo "POSTGRES=/usr/lib/postgresql/${{ env.PG_VERSION }}/bin" >> $GITHUB_ENV

      - name: Install pgcopydb
        run: |
          sudo apt update
          sudo apt install -y pgcopydb

      - name: Clean previous dump
        run: rm -rf $PG_WORK_DIR && mkdir -p $PG_WORK_DIR

      - name: Dump schema from production
        run: |
          pgcopydb dump schema \
            --source=${{ env.PROD_DATABASE_URL }} \
            --dir=$PG_WORK_DIR

      - name: Drop tables and schema
        run: |
          echo "Dropping existing schema and tables in development"
          $POSTGRES/psql "${{ env.DEV_DATABASE_URL }}" -c "DROP SCHEMA IF EXISTS public CASCADE;"
          $POSTGRES/psql "${{ env.DEV_DATABASE_URL }}" -c "CREATE SCHEMA public;"

      - name: Restore schema to development
        run: |
          echo "Restoring schema to development"
          pgcopydb restore pre-data \
            --source=${{ env.PROD_DATABASE_URL }} \
            --target=${{ env.DEV_DATABASE_URL }} \
            --dir=$PG_WORK_DIR

      - name: Create filter file for selective data copy
        run: |
          echo '{
            "includeOnlyTableData": [
              {
                "table": "users",
                "where": "id IN (SELECT id FROM users ORDER BY id DESC LIMIT 50)"
              }
            ]
          }' > $PG_WORK_DIR/filters.json

      - name: Copy data (latest 50 users)
        run: |
          echo "Copying selective data"
          pgcopydb copy table-data \
            --source=${{ env.PROD_DATABASE_URL }} \
            --target=${{ env.DEV_DATABASE_URL }} \
            --filters $PG_WORK_DIR/filters.json

      - name: Restore post-data (constraints, indexes, triggers)
        run: |
          echo "Restoring post-data (constraints, indexes, triggers)"
          pgcopydb restore post-data \
            --source=${{ env.PROD_DATABASE_URL }} \
            --target=${{ env.DEV_DATABASE_URL }} \
            --dir=$PG_WORK_DIR \
            --no-owner

      - name: Debugging - List workspace files
        run: ls -lah ${{ github.workspace }}
